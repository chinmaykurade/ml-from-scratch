{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X, y)\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 13), (178,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_gini_impurity(y):\n",
    "#     gini = 0\n",
    "#     total = len(y)\n",
    "\n",
    "#     n_classes = len(set(y))\n",
    "#     counts = Counter(y)\n",
    "    \n",
    "#     for k,v in counts.items():\n",
    "#         gini += (v/total)**2\n",
    "#     gini_impurity = 1 - gini\n",
    "    \n",
    "#     return gini_impurity\n",
    "\n",
    "\n",
    "# def calculate_entropy(y):\n",
    "#     entropy = 0\n",
    "#     total = len(y)\n",
    "\n",
    "#     n_classes = len(set(y))\n",
    "#     counts = Counter(y)\n",
    "    \n",
    "#     for k,v in counts.items():\n",
    "#         p_class = v/total\n",
    "#         # print(p_class)\n",
    "#         entropy += -(p_class) * np.log(p_class) / np.log(2)\n",
    "    \n",
    "#     return entropy\n",
    "\n",
    "\n",
    "# def feature_split_interval(X_feature, interval_granularity=0.2, default_max_len_intervals=5):\n",
    "#     \"\"\"\n",
    "#     Get the intervals for a particular feature to find the gini impurity values for the split.\n",
    "#     \"\"\"\n",
    "#     X_feature = X_feature.reshape(-1,)\n",
    "\n",
    "#     feature_max, feature_min = max(X_feature), min(X_feature)\n",
    "\n",
    "#     max_len_intervals = max(default_max_len_intervals, int(interval_granularity * X_feature.shape[0]))\n",
    "#     # print(max_len_intervals)\n",
    "\n",
    "#     X_feature_sorted = np.sort(X_feature)\n",
    "\n",
    "#     unique_values = np.unique(X_feature)\n",
    "\n",
    "#     if unique_values.shape[0] == 1:\n",
    "#         # print(np.array([unique_values[0]]))\n",
    "#         return np.array([unique_values[0]])\n",
    "#     elif unique_values.shape[0] == 2:\n",
    "#         # print(np.array([unique_values.mean()]))\n",
    "#         return np.array([unique_values.mean()])\n",
    "\n",
    "#     # return X_feature_sorted\n",
    "\n",
    "#     cum_diff = np.roll(X_feature_sorted, -1) - X_feature_sorted\n",
    "#     cum_diff = cum_diff[:-1]\n",
    "#     max_diff, min_diff = max(cum_diff), min(cum_diff)\n",
    "#     median_diff = np.median(cum_diff)\n",
    "#     median_nonzero_diff = np.median(cum_diff[cum_diff!=0])\n",
    "#     min_nonzero_diff = np.min(cum_diff[cum_diff!=0])\n",
    "\n",
    "#     start = feature_min + min_nonzero_diff/2\n",
    "#     end = feature_max - min_nonzero_diff/2\n",
    "#     min_nonzero_diff_interval = np.arange(start, end, min_nonzero_diff)\n",
    "\n",
    "#     # print(start, end, min_nonzero_diff_interval)\n",
    "\n",
    "#     if min_nonzero_diff_interval.shape[0] > max_len_intervals:\n",
    "#         return np.linspace(start, end, max_len_intervals)\n",
    "\n",
    "#     return min_nonzero_diff_interval\n",
    "\n",
    "\n",
    "# def optimal_feature_split(X_feature, y, criterion='gini'):\n",
    "#     split_intervals = feature_split_interval(X_feature)\n",
    "\n",
    "#     if criterion == 'gini':\n",
    "#         parent_node_criterion_value = calculate_gini_impurity(y)\n",
    "#     else:\n",
    "#         parent_node_criterion_value = calculate_entropy(y)\n",
    "\n",
    "#     min_weighted_criterion_value = 1\n",
    "\n",
    "#     # print(split_intervals, X_feature)\n",
    "#     optimal_split_values = [split_intervals[0]]\n",
    "\n",
    "#     for split_value in split_intervals:\n",
    "#         # print(split_value)\n",
    "#         ge_split = y[X_feature >= split_value]\n",
    "#         lt_split = y[X_feature < split_value]\n",
    "\n",
    "#         if criterion == 'gini':\n",
    "#             weighted_criterion_value = (calculate_gini_impurity(lt_split) * len(lt_split) \\\n",
    "#                 + calculate_gini_impurity(ge_split) * len(ge_split))/ len(y)\n",
    "#         else:\n",
    "#             weighted_criterion_value = (calculate_entropy(lt_split) * len(lt_split) \\\n",
    "#                 + calculate_entropy(ge_split) * len(ge_split))/ len(y)\n",
    "        \n",
    "#         if weighted_criterion_value <= min_weighted_criterion_value:\n",
    "#             if weighted_criterion_value == min_weighted_criterion_value:\n",
    "#                 optimal_split_values.append(split_value)\n",
    "#             else:\n",
    "#                 optimal_split_values = [split_value]\n",
    "#                 min_weighted_criterion_value = weighted_criterion_value\n",
    "    \n",
    "#     return np.mean(optimal_split_values), min_weighted_criterion_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node:\n",
    "#     \"\"\"\n",
    "#     A class to represent a node(leaf) of a decision tree.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, X, y, height, max_tree_height, criterion):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.height = height\n",
    "#         self.max_tree_height = max_tree_height\n",
    "#         self.criterion = criterion\n",
    "#         if criterion == 'gini':\n",
    "#             self.criterion_value = calculate_gini_impurity(y)\n",
    "#         else: \n",
    "#             self.criterion_value = calculate_entropy(y)\n",
    "        \n",
    "#         self.num_samples, self.num_features = X.shape\n",
    "#         self.final_class = Counter(y).most_common()[0][0]\n",
    "#         self.left_child = None\n",
    "#         self.right_child = None\n",
    "\n",
    "#         # print(self.gini_impurity)\n",
    "\n",
    "#         if self.criterion_value == 0 or self.height >= max_tree_height:\n",
    "#             self.is_terminal = True\n",
    "#             # print(self.gini_impurity, self.height, self.max_tree_height)\n",
    "#         else:\n",
    "#             self.is_terminal = False\n",
    "#             self.feature_split = random.choice([*range(self.num_features)])\n",
    "#             # print(X[:,self.feature_split])\n",
    "#             split_intervals = feature_split_interval(X[:,self.feature_split])\n",
    "#             # print(split_intervals)\n",
    "#             self.split_value = np.random.choice(split_intervals)\n",
    "        \n",
    "#         # print(X.shape, y.shape, self.criterion_value, self.is_terminal)\n",
    "\n",
    "\n",
    "#     def fit(self):\n",
    "#         # print(self.X.shape)\n",
    "#         min_criterion_value = 1\n",
    "#         for i in range(self.num_features):\n",
    "#             split_value, split_criterion_value = optimal_feature_split(self.X[:,i], self.y, criterion=self.criterion)\n",
    "#             if split_criterion_value < min_criterion_value:\n",
    "#                 min_criterion_value = split_criterion_value\n",
    "#                 best_feature = i\n",
    "#                 best_feature_split_value = split_value\n",
    "        \n",
    "#         X_feature = self.X[:, best_feature]\n",
    "        \n",
    "#         X_lt = self.X[X_feature < best_feature_split_value, :]\n",
    "#         X_ge = self.X[X_feature >= best_feature_split_value, :]\n",
    "\n",
    "#         y_lt = self.y[X_feature < best_feature_split_value]\n",
    "#         y_ge = self.y[X_feature >= best_feature_split_value]\n",
    "\n",
    "#         self.feature_split = best_feature\n",
    "#         self.split_value = best_feature_split_value\n",
    "#         self.split_criterion_value = min_criterion_value\n",
    "\n",
    "#         # print(best_feature, best_feature_split_value, min_gini_impurity, self.height)\n",
    "\n",
    "#         if self.criterion_value <= min_criterion_value:\n",
    "#             # This means the split did not improve the criteron - gini impurity, we need to stop\n",
    "#             return self\n",
    "\n",
    "#         self.left_child = Node(X_lt, y_lt, self.height+1, self.max_tree_height, self.criterion)\n",
    "#         self.right_child = Node(X_ge, y_ge, self.height+1, self.max_tree_height, self.criterion)\n",
    "\n",
    "#         if not self.left_child.is_terminal:\n",
    "#             self.left_child.fit()\n",
    "\n",
    "#         if not self.right_child.is_terminal:\n",
    "#             self.right_child.fit()\n",
    "\n",
    "#         return self\n",
    "\n",
    "\n",
    "#     def predict_sample(self, X_sample):\n",
    "#         if self.is_terminal:\n",
    "#             return self.final_class\n",
    "#         if X_sample[self.feature_split] >= self.split_value:\n",
    "#             # Pass on to the right child\n",
    "#             if self.right_child is not None:\n",
    "#                 return self.right_child.predict_sample(X_sample)\n",
    "#             else:\n",
    "#                 return self.final_class\n",
    "#         else:\n",
    "#             if self.left_child is not None:\n",
    "#                 return self.left_child.predict_sample(X_sample)\n",
    "#             else:\n",
    "#                 return self.final_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecisionTreeClassifier:\n",
    "#     \"\"\"\n",
    "#     A Decision Tree Classifier Machine Learning algorithm.\n",
    "\n",
    "#     Parameters:\n",
    "#         max_depth (int): The maximum depth of the decision tree\n",
    "#         criterion (str): The criterion for splitting - 'gini' or 'information gain'\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, max_depth: int=20, criterion: str='gini'):\n",
    "#         self.max_depth = max_depth\n",
    "#         self.criterion = criterion\n",
    "\n",
    "\n",
    "#     def fit(self, X: np.array, y: np.array):\n",
    "#         n_samples, n_features = X.shape\n",
    "#         assert n_samples == y.shape[0]\n",
    "#         assert len(y.shape) == 1 or y.shape[1] == 1\n",
    "\n",
    "#         self.root_node = Node(X, y, 1, self.max_depth, self.criterion)\n",
    "#         self.root_node.fit()\n",
    "\n",
    "#         return self\n",
    "\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         y_pred = np.array([self.root_node.predict_sample(X_sample) for X_sample in X])\n",
    "#         return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree.decision_tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9924812030075187, 0.8444444444444444)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5, criterion='information_gain')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8222222222222222)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5, criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8666666666666667)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9555555555555556)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5287ba08fa44ac65bd615339e8b20f6184d001330af1d1c7cfe837ba2d07d6ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
