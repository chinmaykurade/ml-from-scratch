{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier as sklDecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X, y)\n",
    "# iris.keys()\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_wine\n",
    "# wine = load_wine()\n",
    "# X, y = wine.data, wine.target\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.8888888888888888\n",
      "1.0 0.8666666666666667\n",
      "1.0 0.8666666666666667\n",
      "1.0 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "from tree.decision_tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred))\n",
    "clf = DecisionTreeClassifier(max_depth=5, criterion='gini', extreme_random=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred))\n",
    "clf = sklDecisionTreeClassifier(max_depth=5, criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred))\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    A Random Forest Classifier Machine Learning algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        n_estimators (int): The number of decision trees to use\n",
    "        max_tree_depth (int): The maximum depth of the component decision tree\n",
    "        criterion (str): The criterion for splitting - 'gini' or 'entropy'\n",
    "        max_features_split (float): The maximum number of features to consider for making a decision tree split (default=number of features)\n",
    "        extreme_random (bool): Whether to use randomly generated thresholds for splitting (default=False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "        n_estimators: int=100, \n",
    "        max_tree_depth: int=20, \n",
    "        criterion: str='gini',\n",
    "        max_features_split: int=None,\n",
    "        extreme_random: bool=False\n",
    "        ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        self.criterion = criterion\n",
    "        self.max_features_split = max_features_split\n",
    "        self.extreme_random = extreme_random\n",
    "\n",
    "\n",
    "    def generate_random_decision_trees(self, X, y, n_estimators, max_features_split, random_state=100):\n",
    "        print(n_estimators)\n",
    "        estimators = []\n",
    "        for _ in range(n_estimators):\n",
    "            features_to_skip = []\n",
    "            if self.max_features_split is not None:\n",
    "                # print(self.n_features, self.n_features-self.max_features_split)\n",
    "                features_to_skip = list(np.random.choice(self.n_features, self.n_features-self.max_features_split, replace=False))\n",
    "                # print(features_to_skip)\n",
    "\n",
    "            clf = DecisionTreeClassifier(\n",
    "                max_depth=self.max_tree_depth, \n",
    "                criterion=self.criterion, \n",
    "                features_to_skip=features_to_skip,\n",
    "                extreme_random=self.extreme_random\n",
    "                )\n",
    "            random_indices = np.random.choice(X.shape[0], X.shape[0], replace=True)\n",
    "            X_sample = X[random_indices]\n",
    "            y_sample = y[random_indices]\n",
    "            clf.fit(X_sample, y_sample)\n",
    "            estimators.append(clf)\n",
    "        return estimators\n",
    "\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array):\n",
    "        n_samples, n_features = X.shape\n",
    "        assert n_samples == y.shape[0]\n",
    "        assert len(y.shape) == 1 or y.shape[1] == 1\n",
    "\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "\n",
    "        self.num_classes = len(Counter(y))\n",
    "\n",
    "        self.estimators = self.generate_random_decision_trees(X, y, self.n_estimators, self.max_features_split)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_preds = [clf.predict(X) for clf in self.estimators]\n",
    "        y_preds = [np.squeeze(np.eye(self.num_classes)[a.reshape(-1)]) for a in y_preds]\n",
    "        y_pred_proba = np.array(y_preds).mean(axis=0)\n",
    "\n",
    "        return y_pred_proba\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        y_pred = y_pred_proba.argmax(axis=1)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1.0 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, criterion='gini', extreme_random=False, max_features_split=8)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5287ba08fa44ac65bd615339e8b20f6184d001330af1d1c7cfe837ba2d07d6ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
